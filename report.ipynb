{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Movie Review Sentiment Prediction\n",
    "\n",
    "This report is written with jupyter notebook and converted to pdf, so if you have jupyter installed, you can run the file report.ipynb.\n",
    "\n",
    "Use nltk to tokenize and count the number of each words. For information on installation see README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Use os.listdir to find all file names and then iterate throught them and read each file into a string, omitting linebreaks and apostrophes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_dir_pos = 'review_polarity/txt_sentoken/pos'\n",
    "reviews_dir_neg = 'review_polarity/txt_sentoken/neg'\n",
    "pos_reviews = os.listdir(reviews_dir_pos)\n",
    "neg_reviews = os.listdir(reviews_dir_neg)\n",
    "\n",
    "positive_str = []\n",
    "negative_str = []\n",
    "# read in positive reviews\n",
    "for review in pos_reviews:\n",
    "    with open(os.path.join(reviews_dir_pos, review), 'r') as file:\n",
    "        review_str = file.read().replace('\\n', '').replace(\"'\", '')\n",
    "        positive_str.append(review_str)\n",
    "        \n",
    "for review in neg_reviews:\n",
    "    with open(os.path.join(reviews_dir_neg, review), 'r') as file:\n",
    "        review_str = file.read().replace('\\n', '')\n",
    "        negative_str.append(review_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of all words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common 60 words in all reviews are: \n[('the', 76528), ('a', 38100), ('and', 35576), ('of', 34123), ('to', 31937),\n ('is', 25195), ('in', 21822), ('that', 15566), ('it', 14200), ('as', 11378),\n ('with', 10792), ('for', 9961), ('his', 9587), ('this', 9577), ('film', 9196),\n ('s', 9077), ('but', 8634), ('he', 8267), ('i', 8259), ('on', 7382),\n ('are', 6949), ('by', 6261), ('be', 6173), ('one', 5816), ('an', 5744),\n ('movie', 5665), ('not', 5577), ('who', 5548), ('from', 4999), ('at', 4986),\n ('you', 4943), ('was', 4940), ('have', 4901), ('has', 4719), ('they', 4614),\n ('her', 4522), ('all', 4373), ('its', 4163), ('like', 3690), ('so', 3683),\n ('out', 3637), ('t', 3628), ('about', 3522), ('up', 3405), ('there', 3364),\n ('more', 3347), ('when', 3258), ('what', 3233), ('which', 3161), ('or', 3146),\n ('their', 3122), ('some', 2985), ('she', 2941), ('just', 2905), ('if', 2799),\n ('him', 2633), ('into', 2623), ('can', 2607), ('we', 2595), ('even', 2565)]\n============================================\nTotal number of unique words left in the word set: 41018\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "mega_str = ''.join(positive_str + negative_str)\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "all_count = Counter(tokenizer.tokenize(mega_str))\n",
    "\n",
    "pp = pprint.PrettyPrinter(width=80, compact=True)\n",
    "print('The most common {} words in all reviews are: '.format(60))\n",
    "top_common = all_count.most_common(60)\n",
    "pp.pprint(top_common)\n",
    "\n",
    "# delete top 60 common words\n",
    "for key in list(zip(*top_common))[0]:\n",
    "    del all_count[key]\n",
    "\n",
    "print('============================================')\n",
    "print('Total number of unique words left in the word set: {}'.format(len(all_count)))\n",
    "\n",
    "feature_keys = list(dict(all_count).keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, we've got our feature list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tokens = []\n",
    "neg_tokens = []\n",
    "\n",
    "# for each review find and delete top 10 common words\n",
    "for review in positive_str:\n",
    "    count = dict(Counter(tokenizer.tokenize(review)))\n",
    "    feature_dict = {}\n",
    "    for key in feature_keys:\n",
    "        if key in count:\n",
    "            feature_dict[key] = count[key]\n",
    "        else:\n",
    "            feature_dict[key] = 0\n",
    "    pos_tokens.append(feature_dict)\n",
    "    \n",
    "for review in negative_str:\n",
    "    count = dict(Counter(tokenizer.tokenize(review)))\n",
    "    for key in feature_keys:\n",
    "        if key in count:\n",
    "            feature_dict[key] = count[key]\n",
    "        else:\n",
    "            feature_dict[key] = 0\n",
    "    neg_tokens.append(feature_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step: shuffle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(pos_tokens)):\n",
    "    pos_tokens[i]['@'] = 1\n",
    "    \n",
    "for i in range(0, len(neg_tokens)):\n",
    "    neg_tokens[i]['@'] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step: shuffle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "features = pos_tokens + neg_tokens\n",
    "print('Total number of reviews: {}, each has {} features'.format(len(features),\n",
    "                                                                 len(features[0])-1))\n",
    "\n",
    "shuffle(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(0, len(features)):\n",
    "    labels.append(features[i]['@'])\n",
    "\n",
    "for entry in features:\n",
    "    try:\n",
    "        del entry['@']\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Training the perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-352-999fa23a6b8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/snowman/Documents/ml_c/hw_1/learner/perceptron.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, alpha, verbose)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \"\"\"\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from learner.perceptron import Perceptron\n",
    "\n",
    "features_list = [list(entry.values()) for entry in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-352-999fa23a6b8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/snowman/Documents/ml_c/hw_1/learner/perceptron.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, alpha, verbose)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \"\"\"\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "clf = Perceptron()\n",
    "print(clf.train(features_list, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}